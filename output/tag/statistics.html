<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Sociological Gobbledygook - statistics</title>
        <link rel="stylesheet" href="https://sociologicalgobbledygook.com/theme/css/main.css" />
        <link rel="stylesheet" href="https://sociologicalgobbledygook.com/theme/css/juptyer-fix.css" />
        <link href="https://sociologicalgobbledygook.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Sociological Gobbledygook Atom Feed" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://sociologicalgobbledygook.com/">Sociological Gobbledygook </a></h1>
                <nav><ul>
                    <li><a href="https://sociologicalgobbledygook.com/pages/manifesto.html">Manifesto</a></li>
                    <li><a href="https://sociologicalgobbledygook.com/pages/syllabus.html">Syllabus</a></li>
                    <li><a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a></li>
                    <li><a href="https://sociologicalgobbledygook.com/category/welcome.html">Welcome</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="https://sociologicalgobbledygook.com/p-values-and-bayes-rule-draft.html">P-Values and Bayes Rule (draft)</a></h1>
<footer class="post-info">
        <abbr class="published" title="2018-12-10T00:00:00-06:00">
                Published: Mon 10 December 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://sociologicalgobbledygook.com/author/paul-gowder.html">Paul Gowder</a>
        </address>
<p>In <a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a>.</p>
<p>tags: <a href="https://sociologicalgobbledygook.com/tag/statistics.html">statistics</a> <a href="https://sociologicalgobbledygook.com/tag/conceptual.html">conceptual</a> </p>
</footer><!-- /.post-info --><p>Recall from the previous lesson what a p-value is: it’s the probability of observing a value of your statistic as extreme (as far away from the null hypothesis statistic) as you in fact observed, if the null hypothesis were true.  </p>
<p>In other words, if you’re doing a (two-sided) z test, your statistic is the mean, your null hypothesis mean is <span class="math">\(\mu\)</span>, and the mean you observe in your sample is <span class="math">\(\bar{x}\)</span>, then the p-value is the probability of getting a mean at least <span class="math">\(\mu - \bar{x}\)</span> units away from the mean when randomly sampling from a normal distribution with mean <span class="math">\(\mu\)</span> and standard deviation estimated by the formula for the standard deviation of a sample. (We’ll talk about that formula later, but if you want a sneak preview, check out <a href="https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/variance-standard-deviation-sample/a/population-and-sample-standard-deviation-review">this Khan Academy article</a>.) If the p-value is below a predetermined level, often 0.05, then we say that there’s a statistically significant result. </p>
<p>Pause for a moment and ask yourself the following question: <strong>Does that mean the p-value is the probability of incorrectly rejecting the null hypothesis?</strong> Don’t go on until you have an answer, and can explain why you have that answer. This is very important.</p>
<p>Incidentally, that’s called a "Type I error" in some circles: the error of incorrectly rejecting the null hypothesis, a.k.a. (if you’re sensible and don’t like double negatives) convincing yourself that you’re seeing a real effect when you’re not. So the question above could be rephrased: "Is the p-value the probability of making a Type I error?"  A Type II error is the opposite: failing to reject the null hypothesis when you oughta, or, in other words, seeing a real effect and not realizing it. There’s a particularly good meme that captures this distinction and makes it impossible to forget:</p>
<p><img src="https://4.bp.blogspot.com/-wmZzvsY_Tec/Vws0f4MJn9I/AAAAAAAAORs/gipKxA7aDboP0gx2vSmyQS_ZoVBPzqaWA/s1600/Type%2BI%2Band%2BII%2Berror.jpg" alt="Type I and Type II errors" width="100%"/></p>
<p>So, what’s your answer?  I’ll make some more space just to make sure you have a chance to figure it out for yourself...</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>The answer to my question is <strong>no.</strong> Here’s why.</p>
<p>If you go back to the definition I gave you of p-values, you’ll see that it’s really a conditional probability. The p value is the probability of seeing the data in your sample, conditional on the null hypothesis being true. In symbols: </p>
<div class="math">$$PValue = P(DataSeen|NullHypothesis)$$</div>
<p>But what you'd really like to know is the probability of making a Type I error--the probability of making a mistake and declaring that you’ve discovered something that isn’t. Unfortunately, that can be rephrased as <strong>the probability of the null hypothesis being true, conditional on seeing your data!</strong>  In symbols: </p>
<div class="math">$$P(TypeIError) = P(NullHypothesis|DataSeen)$$</div>
<p>By now, you should know that you can’t flip conditional probabilities around like that. Yet this is an incredibly common mistake--even actual statistics teachers sometimes slip up and say that the p-value is the probability of making a Type I error.  It isn’t!  Never say this! Never think this! Never respect anyone who does say or think it!</p>
<p>Here's an intuitive way of thinking about the problem. A statistically significant p-value means "if the null hypothesis were true, it would be unlikely that I'd have seen a sample that looks like that." There are some <a href="https://www.census.gov/popclock/">328 million</a> U.S. citizens, and 535 members of Congress. So, if you randomly sample 100 Americans without replacement, it's really unlikely that they're all going to be members of Congress.  </p>
<p>How unlikely? Well, we'll want the number of possible samples of 100 members of Congress, divided by the number of possible 100-person samples: that's <span class="math">\({535\choose 100}\)</span> divided by <span class="math">\({328,000,000\choose 100}\)</span> which is... a lot. Let's not try and do this by hand, eh?  (The parens mean, e.g., "535 choose 100"---see <a href="https://math.stackexchange.com/questions/1688391/probability-of-picking-4-red-balls">this explanation</a> of the general process of reasoning here. Here's the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.comb.html#scipy.special.comb">Python function</a> we're going to use.). This produces a probability so small that we have to use a fancy arbitrary precision math library called <code>mpmath</code> to get it to actually do the division. </p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">comb</span> 
<span class="kn">import</span> <span class="nn">mpmath</span> 
<span class="n">numerator</span> <span class="o">=</span> <span class="n">mpmath</span><span class="o">.</span><span class="n">mpf</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="mi">535</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span> 
<span class="n">denominator</span> <span class="o">=</span> <span class="n">mpmath</span><span class="o">.</span><span class="n">mpf</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="mi">328000000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span> 
<span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span>
</pre></div>


<p>And we get <code>9.0061113088164994e-584</code> which, in real human speak, is .9 with 584 zeroes between the decimal point and the 9... that is, significantly less likely than picking a particular atom in randomly sampling from every atom in the known universe. </p>
<p>So if I'm sampling Americans, it's vanishingly unlikely that that I get a sample with 100 members of Congress. <span class="math">\(P(Draw100Congress|Draw100Americans)\)</span> is that tiny number up above.  But it obviously does not follow that <span class="math">\(P(Draw100Americans|Draw100Congress)\)</span> is small. Indeed that second probability statement is 1, or damn close to it (even though the Constitution requires members of Congress be citizens, you might imagine some incredibly unlikely event like someone getting elected to Congress after successfully deceiving the public about his/her citizenship status). In other words, I <em>absolutely cannot</em> infer from the unlikelihood of getting all members of Congress in my sample of Americans that it is unlikely that I had sampled Americans, given that I saw all members of Congress (Incidentally, I adapted this example from Cohen, 1994, <a href="http://psycnet.apa.org/doiLanding?doi=10.1037%2F0003-066X.49.12.997">The Earth is Round (p&lt;.05)</a>, who in turn adapted it from Pollard &amp; Richardson, 1987, <a href="http://psycnet.apa.org/record/1987-30223-001">"On the Probability of Making Type I Errors"</a>.)  </p>
<p>Here’s why this matters. In reality, many, many studies with a "statistically significant" p-value are likely to nonetheless be Type I errors. The reason is because the actual probability of a Type I error depends on the prior likelihood that the null hypothesis was false in the first place, as well as on how likely it is that you'd see your data (in other words, on the base rate). Let’s flesh this out some more with Bayes Rule. Remember it? </p>
<div class="math">$$P(B|A) = \frac{P(A|B) \cdot P(B)}{P(A)}$$</div>
<p>As applied here, plugging in our concepts from above:</p>
<div class="math">$$P(TypeIError) \frac{PValue \cdot P(NullHypothesis)}{P(DataSeen)}$$</div>
<p>What does that mean?  Well, first of all, it means that in order to even take a wild guess at how likely it is that we’re making a Type I error, we have to know how likely our null hypothesis is (in Bayesian terms, we have to have a prior probability in our heads about it). If we have strong prior reason to believe our null hypothesis--if our alternative hypothesis, or the research finding we’re trying to test out, is really crazy, then we ought to conclude that it’s more likely that we’re making a Type I error, even in the face of a statistically significant p-value. For example, if you think you’ve provided evidence for psychic abilities, as <a href="https://www.theguardian.com/science/head-quarters/2016/oct/31/did-a-memory-experiment-really-show-evidence-for-psychic-abilities">occasionally shows up in psychology journals</a>, you should probably estimate your probability of making a Type I error as quite high, because your prior on Dr. Xavier running around somewhere controlling stuff <em>with his miiiiiind</em> is pretty small (or at least oughta be).</p>
<p>Second, you’d need to have some idea of the base rate of the data you observed in your sample (the denominator above). If it’s low, then that makes it more likely that we’re making a Type I error. Recall from our probability lesson that we can calculate that via the <a href="https://en.m.wikipedia.org/wiki/Law_of_total_probability">law of total probability</a> as follows: </p>
<div class="math">$$P(DataSeen) = P(DataSeen|NullHypothesis) \cdot P(NullHypothesis) + \\P(DataSeen|AlternativeHypothesis) \cdot P(AlternativeHypothesis)$$</div>
<p>How can that value be low? Well, one important way is that <span class="math">\(P(DataSeen|AlternativeHypothesis)\)</span> could be low. In other words: sure, it might be that it’s really unlikely that you’d see the data you saw if your null hypothesis were true. But what if it’s <em>even more unlikely</em> that you’d see the data you saw if your alternative hypothesis were true?! A low p-value means that the data you saw would come up pretty rarely in that null distribution.  But what if it would come up even more rarely in every other plausible distribution? This is the lesson of our Congress example: <span class="math">\(P(Draw100Congress|Draw100Foreigners)\)</span> is much smaller even than the tiny number we got for <span class="math">\(P(Draw100Congress|Draw100Americans)\)</span>.</p>
<p>What this suggests is that the construction of the hypotheses really matter. Let's return to the Congress example. Suppose my null hypothesis was "this sample was constructed from the general population of Americans," and the alternative hypothesis was "this sample was constructed from the population of people found in the U.S. Capitol on the day of the State of the Union Address." Well, now, it seems like maybe the composition of our sample tells us something useful.  Because <span class="math">\(P(Draw100Congress|Draw100FromCapitol)\)</span> is probably pretty big, relatively speaking.</p>
<p>Here’s what this all comes down to: </p>
<ul>
<li>Often we don’t really know these other terms that go into the Bayes Rule equation to go from p-values to probabilities of Type I errors. </li>
<li>Sometimes, prior theories of how the world works (like psychic powers not being real) can give us broad guesses for those other terms, which can give us a rough idea of how confident we should be in our results. This is part of why statistics folks look down on the practice of "data-mining," a.k.a., hunting through data without a theory looking for significant results. </li>
<li>The only way to be really confident that empirical results are real is by replicating them--by getting significant results again and again from different samples. </li>
<li>Don’t trust that a result is real just because it has a statistically significant p-value!</li>
<li>If some expert witness shows you a p-value of 0.05 and says "there's a 95% chance the null is false," you should laugh derisively at them and then fire them if they're your expert or cross examine them into oblivion if they're someone else's.</li>
</ul>
<p>Further readings, if you’d like to learn more: </p>
<ul>
<li>F. Perry Wilson <a href="https://www.medpagetoday.com/Blogs/TheMethodsMan/52171">The P-Value is a Hoax, But Here's How to Fix it</a>---This is an amazing concrete illustration with actual numbers of the point above about base rates.  Actually, you know what?  That's so good I'm going to quote it at length: </li>
</ul>
<blockquote>
<p>Let's say that there are 100,000 hypotheses out there -- floating in the ether. Some of the hypotheses are true, some are false (this is how science works, right?). It turns out that it's the proportion of true hypotheses that dictates how much of the medical literature is nonsense, not the p-value. Let me prove it.</p>
<p>Let's say that of our 100,000 hypotheses, 10%, or 10,000 are true. I may be a bit of a pessimist but I think I'm being pretty generous here. OK -- how many false positives will there be? Well, of the 90,000 false hypotheses, 5% (there's the p-value!) will end up appearing true in the study by chance alone. Five percent of 90,000 is 4,500 false positive studies. How many true positives will there be? Well, we have 10,000 true hypotheses -- but not all the studies will be positive. The number of positive studies will depend on how adequately "powered" they are, and power is usually set at around 80%, meaning that 8,000 of those true hypotheses will be discovered to be true when tested, while 2,000 will be missed.</p>
<p>So of our 100,000 hypotheses, we have a total of 12,500 positive studies. 4,500 of those 12,500 are false positives. That's 36%. [...]</p>
<p>Let that sink in. Despite the comforting nature of the 0.05 threshold for the p-value, 36% of the positive studies you read may be false.</p>
<p>This depends critically on the number of true hypotheses by the way. If I drop the number of true hypotheses to 5%, keeping everything else the same, then 55% of the positive studies you read are wrong. It's a disaster.</p>
</blockquote>
<p>(n.b.: we'll talk about the "power" thing later on in the class.)</p>
<ul>
<li>
<p>Minitab blog, "<a href="http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values">How to Correctly Interpret P Values</a>" (Minitab is a statistical software package, and the editor of its blog is on a lovely quest to comprehensibly explain the whole p-value thing).</p>
</li>
<li>
<p>538 blog post <a href="https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/">complaining that nobody can explain p-values comprehensibly</a>. (Mostly included because the best explanation the 538 blogger could find was from Stuart Buck... who is not only a lawyer, he was actually my law school classmate. Lawyers can understand this stuff!) </p>
</li>
<li>
<p>John Ioannidis, "<a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Why Most Published Research Findings are False</a>" (sort of a more complicated and less clear version of the Perry Wilson blog post above).</p>
</li>
<li>
<p>David Papineau, "<a href="https://www.the-tls.co.uk/articles/public/thomas-bayes-science-crisis/">Thomas Bayes and the Crisis in Science</a>", Times Literary Supplement.</p>
</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "left",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'blue ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('Typewriter' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_Typewriter');" +
                "VARIANT['bold'].fonts.unshift('MathJax_Typewriter-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_Typewriter-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_Typewriter-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_Typewriter');" +
                "VARIANT['bold'].fonts.unshift('MathJax_Typewriter-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_Typewriter-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_Typewriter-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="https://sociologicalgobbledygook.com/hypothesis-testing-conceptual-introduction-draft.html" rel="bookmark"
                           title="Permalink to Hypothesis Testing: Conceptual Introduction (draft)">Hypothesis Testing: Conceptual Introduction (draft)</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-12-09T00:00:00-06:00">
                Published: Sun 09 December 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://sociologicalgobbledygook.com/author/paul-gowder.html">Paul Gowder</a>
        </address>
<p>In <a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a>.</p>
<p>tags: <a href="https://sociologicalgobbledygook.com/tag/statistics.html">statistics</a> <a href="https://sociologicalgobbledygook.com/tag/conceptual.html">conceptual</a> </p>
</footer><!-- /.post-info -->                <p>Now that we understand distributions and the central limit theorem, we’re in a good position to make sense of the notion of a hypothesis test. It’s actually very simple. </p>
<p>Suppose you do an experiment. Let’s say you want to find out whether a company is engaging in …</p>
                <a class="readmore" href="https://sociologicalgobbledygook.com/hypothesis-testing-conceptual-introduction-draft.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://sociologicalgobbledygook.com/lesson-22-the-basics-of-probability.html" rel="bookmark"
                           title="Permalink to Lesson 2.2 The Basics of Probability">Lesson 2.2 The Basics of Probability</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-12-08T00:00:00-06:00">
                Published: Sat 08 December 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://sociologicalgobbledygook.com/author/paul-gowder.html">Paul Gowder</a>
        </address>
<p>In <a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a>.</p>
<p>tags: <a href="https://sociologicalgobbledygook.com/tag/statistics.html">statistics</a> <a href="https://sociologicalgobbledygook.com/tag/week2.html">week2</a> <a href="https://sociologicalgobbledygook.com/tag/probability.html">probability</a> </p>
</footer><!-- /.post-info -->                <h2>What is Probability?</h2>
<p>Probability is the mathematical representation of the likelihood of an event under a given set of circumstances (conditions) in a given period of time. We will say, for example, that the probability of winning the jackpot in the lottery from buying one ticket this week is some …</p>
                <a class="readmore" href="https://sociologicalgobbledygook.com/lesson-22-the-basics-of-probability.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://sociologicalgobbledygook.com/introduction-to-distributions.html" rel="bookmark"
                           title="Permalink to Introduction to Distributions">Introduction to Distributions</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-12-03T00:00:00-06:00">
                Published: Mon 03 December 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://sociologicalgobbledygook.com/author/paul-gowder.html">Paul Gowder</a>
        </address>
<p>In <a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a>.</p>
<p>tags: <a href="https://sociologicalgobbledygook.com/tag/distributions.html">distributions</a> <a href="https://sociologicalgobbledygook.com/tag/statistics.html">statistics</a> </p>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What's-a-Distribution,-Anyway?">What's a Distribution, Anyway?<a class="anchor-link" href="#What's-a-Distribution,-Anyway?">&#182;</a></h2><p>Statistics people often talk about distributions, like a normal distribution. Here's what they mean: suppose you could see all of the instances of the thing you're trying to study. What kind of pattern would their values have? That's the distribution.</p>
<p>For example, suppose you expect that most of the values of the thing you care about will be clustered around some average value. IQ is a good example: most IQs in the population are around 100, and then as values get further away from 100 in either direction, the fraction of the total number of instances that takes that range of values gets smaller. There are lots of folks with an IQ between 85 and 115, fewer between 70 and 85 on one side, and 115 and 130, many fewer between 55 and 70 or 130 and 145, and a (proportionally) truly tiny number between 40-55 or 145-160.</p>
                <a class="readmore" href="https://sociologicalgobbledygook.com/introduction-to-distributions.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://sociologicalgobbledygook.com/the-normal-distribution-and-the-central-limit-theorem.html" rel="bookmark"
                           title="Permalink to The Normal Distribution and the Central Limit Theorem">The Normal Distribution and the Central Limit Theorem</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-12-03T00:00:00-06:00">
                Published: Mon 03 December 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://sociologicalgobbledygook.com/author/paul-gowder.html">Paul Gowder</a>
        </address>
<p>In <a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a>.</p>
<p>tags: <a href="https://sociologicalgobbledygook.com/tag/distributions.html">distributions</a> <a href="https://sociologicalgobbledygook.com/tag/statistics.html">statistics</a> </p>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The main reason scientists like the normal distribution so much is because of a little thing called the <strong>central limit theorem (CLT)</strong>.</p>
<p>I'm not going to walk you through a tedious proof of the CLT; instead, we'll just look at some graphs and talk about some intuition.</p>
<p>The core idea of the CLT is this: imagine there is a quantity of interest out there in the world, and it is distributed according to any arbitrary distribution, and you want to know the mean. For example, suppose you are interested in knowing the average income in the United States. We known, empirically, that incomes tend to be distributed according to a lognormal distribution.</p>
                <a class="readmore" href="https://sociologicalgobbledygook.com/the-normal-distribution-and-the-central-limit-theorem.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://sociologicalgobbledygook.com/lesson-21-why-statistics-for-lawyers.html" rel="bookmark"
                           title="Permalink to Lesson 2.1 Why Statistics for Lawyers?">Lesson 2.1 Why Statistics for Lawyers?</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-11-03T00:00:00-05:00">
                Published: Sat 03 November 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://sociologicalgobbledygook.com/author/paul-gowder.html">Paul Gowder</a>
        </address>
<p>In <a href="https://sociologicalgobbledygook.com/category/lessons.html">Lessons</a>.</p>
<p>tags: <a href="https://sociologicalgobbledygook.com/tag/statistics.html">statistics</a> <a href="https://sociologicalgobbledygook.com/tag/week2.html">week2</a> <a href="https://sociologicalgobbledygook.com/tag/conceptual.html">conceptual</a> </p>
</footer><!-- /.post-info -->                <p>The brunt of this course will be devoted to statistics and exploratory data analysis. </p>
<p><em>Exploratory data analysis</em> is just looking at data to see what you see.  We will spend some time, for example, looking at how to see the shape of data and what that can tell you about …</p>
                <a class="readmore" href="https://sociologicalgobbledygook.com/lesson-21-why-statistics-for-lawyers.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://law.uiowa.edu/">University of Iowa College of Law</a></li>
                            <li><a href="https://gowder.io">Paul Gowder</a></li>
                            <li><a href="http://python.org/">Python Documentation</a></li>
                            <li><a href="https://github.com/paultopia/quantitative-methods-for-lawyers/">Course Github</a></li>
                            <li><a href="https://notebooks.azure.com/">Microsoft Azure Notebooks</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="https://sociologicalgobbledygook.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
            <address id="about" class="vcard body">
                

                All content is (c) 2018-9 by <a href="https://gowder.io">Paul Gowder</a> and licensed under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International license</a>.  On the technical side, the site is powered by <a href="http://getpelican.com/">Pelican</a>, the theme is a modified version of one by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>.
            </address><!-- /#about -->

                
        </footer><!-- /#contentinfo -->

</body>
</html>